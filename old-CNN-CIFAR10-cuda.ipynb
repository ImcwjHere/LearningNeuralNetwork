{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1, 2, 3], [1, 2, 3]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_datasets = datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=False)\n",
    "test_datasets = datasets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor(), download=False)\n",
    "train_data = DataLoader(train_datasets, batch_size=batch_size, shuffle=True)\n",
    "test_data = DataLoader(test_datasets, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deer\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(test_data))\n",
    "plt.imshow(images[0].permute(1, 2, 0))\n",
    "print(description[labels[0].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 16.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def caculate_infos(size,parameters):\n",
    "    return (parameters[1],((size-parameters[2]+2*parameters[4])/parameters[3])+1)\n",
    "caculate_infos(16,(256,512,3,1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        ) # 64,16*16\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        ) # 128,8*8\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        ) # 256,4*4\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        ) # 512,2*2\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        ) # 1024,2*2\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1024*2*2, 1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.out = nn.Linear(256,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "net = CNN()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: 38.23%\n",
      "发现新的最高精度，保存模型,精度为0.3823\n",
      "epoch 1: 35.66%\n",
      "epoch 2: 38.05%\n",
      "epoch 3: 38.665%\n",
      "发现新的最高精度，保存模型,精度为0.38665\n",
      "epoch 4: 37.580000000000005%\n",
      "epoch 5: 37.915%\n",
      "epoch 6: 39.57%\n",
      "发现新的最高精度，保存模型,精度为0.3957\n",
      "epoch 7: 34.9%\n",
      "epoch 8: 40.129999999999995%\n",
      "发现新的最高精度，保存模型,精度为0.4013\n",
      "epoch 9: 39.129999999999995%\n",
      "epoch 10: 39.635%\n",
      "epoch 11: 38.105%\n",
      "epoch 12: 38.845%\n",
      "epoch 13: 39.900000000000006%\n",
      "epoch 14: 40.635%\n",
      "发现新的最高精度，保存模型,精度为0.40635\n",
      "epoch 15: 38.685%\n",
      "epoch 16: 37.585%\n",
      "epoch 17: 38.945%\n",
      "epoch 18: 39.68%\n",
      "epoch 19: 39.645%\n",
      "epoch 20: 39.89%\n",
      "epoch 21: 40.585%\n",
      "epoch 22: 41.545%\n",
      "发现新的最高精度，保存模型,精度为0.41545\n",
      "epoch 23: 40.550000000000004%\n",
      "epoch 24: 40.96%\n",
      "epoch 25: 40.805%\n",
      "epoch 26: 40.665%\n",
      "epoch 27: 40.53%\n",
      "epoch 28: 39.96%\n",
      "epoch 29: 41.675000000000004%\n",
      "发现新的最高精度，保存模型,精度为0.41675\n",
      "epoch 30: 41.585%\n",
      "epoch 31: 41.175%\n",
      "epoch 32: 41.14%\n",
      "epoch 33: 40.56%\n",
      "epoch 34: 40.89%\n",
      "epoch 35: 39.09%\n",
      "epoch 36: 41.6%\n",
      "epoch 37: 39.715%\n",
      "epoch 38: 41.730000000000004%\n",
      "发现新的最高精度，保存模型,精度为0.4173\n",
      "epoch 39: 42.085%\n",
      "发现新的最高精度，保存模型,精度为0.42085\n",
      "epoch 40: 41.245%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\Desktop\\NeuralNetwork\\cuda-CNN-CIFAR10.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/NeuralNetwork/cuda-CNN-CIFAR10.ipynb#ch0000010?line=32'>33</a>\u001b[0m             torch\u001b[39m.\u001b[39msave(net\u001b[39m.\u001b[39mstate_dict(),\u001b[39m'\u001b[39m\u001b[39mCNN-CIFAR10.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/NeuralNetwork/cuda-CNN-CIFAR10.ipynb#ch0000010?line=33'>34</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m发现新的最高精度，保存模型,精度为\u001b[39m\u001b[39m{\u001b[39;00mmax_record\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/NeuralNetwork/cuda-CNN-CIFAR10.ipynb#ch0000010?line=35'>36</a>\u001b[0m train(\u001b[39m50\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Administrator\\Desktop\\NeuralNetwork\\cuda-CNN-CIFAR10.ipynb Cell 11'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs, learning_rate)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/NeuralNetwork/cuda-CNN-CIFAR10.ipynb#ch0000010?line=4'>5</a>\u001b[0m net\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/NeuralNetwork/cuda-CNN-CIFAR10.ipynb#ch0000010?line=5'>6</a>\u001b[0m \u001b[39m# net.load_state_dict(torch.load('CNN-CIFAR10.pkl'))\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/NeuralNetwork/cuda-CNN-CIFAR10.ipynb#ch0000010?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (images, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_data):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/NeuralNetwork/cuda-CNN-CIFAR10.ipynb#ch0000010?line=7'>8</a>\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/NeuralNetwork/cuda-CNN-CIFAR10.ipynb#ch0000010?line=8'>9</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\cifar.py:115\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torchvision/datasets/cifar.py?line=110'>111</a>\u001b[0m img, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[index]\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torchvision/datasets/cifar.py?line=112'>113</a>\u001b[0m \u001b[39m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torchvision/datasets/cifar.py?line=113'>114</a>\u001b[0m \u001b[39m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torchvision/datasets/cifar.py?line=114'>115</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mfromarray(img)\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torchvision/datasets/cifar.py?line=116'>117</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/torchvision/datasets/cifar.py?line=117'>118</a>\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:2949\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=2945'>2946</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=2946'>2947</a>\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mtostring()\n\u001b[1;32m-> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=2948'>2949</a>\u001b[0m \u001b[39mreturn\u001b[39;00m frombuffer(mode, size, obj, \u001b[39m\"\u001b[39;49m\u001b[39mraw\u001b[39;49m\u001b[39m\"\u001b[39;49m, rawmode, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:2876\u001b[0m, in \u001b[0;36mfrombuffer\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=2872'>2873</a>\u001b[0m         im\u001b[39m.\u001b[39mreadonly \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=2873'>2874</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m im\n\u001b[1;32m-> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=2875'>2876</a>\u001b[0m \u001b[39mreturn\u001b[39;00m frombytes(mode, size, data, decoder_name, args)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:2822\u001b[0m, in \u001b[0;36mfrombytes\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=2818'>2819</a>\u001b[0m     args \u001b[39m=\u001b[39m mode\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=2820'>2821</a>\u001b[0m im \u001b[39m=\u001b[39m new(mode, size)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=2821'>2822</a>\u001b[0m im\u001b[39m.\u001b[39;49mfrombytes(data, decoder_name, args)\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=2822'>2823</a>\u001b[0m \u001b[39mreturn\u001b[39;00m im\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:828\u001b[0m, in \u001b[0;36mImage.frombytes\u001b[1;34m(self, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=825'>826</a>\u001b[0m d \u001b[39m=\u001b[39m _getdecoder(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, decoder_name, args)\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=826'>827</a>\u001b[0m d\u001b[39m.\u001b[39msetimage(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=827'>828</a>\u001b[0m s \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39;49mdecode(data)\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=829'>830</a>\u001b[0m \u001b[39mif\u001b[39;00m s[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/Image.py?line=830'>831</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnot enough image data\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epochs=1, learning_rate=0.001):\n",
    "    max_record = 0.42085 # 手动修改\n",
    "    net.load_state_dict(torch.load('CNN-CIFAR10.pkl'))\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        # net.load_state_dict(torch.load('CNN-CIFAR10.pkl'))\n",
    "        for i, (images, labels) in enumerate(train_data):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total = 10000\n",
    "        correct = 0\n",
    "        net.eval()\n",
    "        for i, (images, labels) in enumerate(test_data):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.tolist()\n",
    "            outputs = net(images)\n",
    "            predict = torch.max(outputs,1).indices.tolist()\n",
    "            total += len(predict)\n",
    "            for i in range(len(predict)):\n",
    "                if predict[i] == labels[i]:\n",
    "                    correct += 1\n",
    "        print(f\"epoch {epoch}: {correct/total*100}%\")\n",
    "        if correct/total>max_record:\n",
    "            max_record = correct/total\n",
    "            torch.save(net.state_dict(),'CNN-CIFAR10.pkl')\n",
    "            print(f\"发现新的最高精度，保存模型,精度为{max_record}\")\n",
    "            \n",
    "train(50, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5.04%\n"
     ]
    }
   ],
   "source": [
    "total = 10000\n",
    "correct = 0\n",
    "for i, (images, labels) in enumerate(test_data):\n",
    "    images = images.to(device)\n",
    "    labels = labels.tolist()\n",
    "    outputs = net(images)\n",
    "    predict = torch.max(outputs,1).indices.tolist()\n",
    "    total += len(predict)\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == labels[i]:\n",
    "            correct += 1\n",
    "print(f\" {correct/total*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_datasets)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3196968d684371006099b3d55edeef8ed90365227a30deaef86e5d4aa8519be0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
